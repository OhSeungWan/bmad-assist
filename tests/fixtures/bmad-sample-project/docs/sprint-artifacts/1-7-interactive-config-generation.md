# Story 1.7: Interactive Config Generation

**Status:** Ready for Review
**Story Points:** 3

---

## Story

**As a** developer,
**I want** CLI questionnaire to generate config when missing,
**So that** first-time setup is guided and user-friendly.

### Business Context

This story completes Epic 1 (Project Foundation & CLI Infrastructure) by implementing interactive configuration generation. When a user runs bmad-assist for the first time without a config file, the CLI guides them through setup via Rich prompts instead of failing with an error.

The questionnaire creates a valid `bmad-assist.yaml` with minimal required settings, enabling fire-and-forget operation from first run.

### Success Criteria

- Running `bmad-assist run` without config triggers interactive questionnaire
- Questionnaire prompts for: CLI provider, Master model selection
- Generated config is saved to `./bmad-assist.yaml` (project-local)
- User can skip questionnaire with `--no-interactive` flag
- Skipping interactive mode with no config exits with clear error message
- Generated config validates against Pydantic models (Story 1.2)

### ðŸš¨ CRITICAL REQUIREMENTS

> **These requirements are NON-NEGOTIABLE. Violation = story failure.**

1. **No Business Logic in CLI Layer** - `cli.py` delegates to config generation, doesn't contain questionnaire logic
2. **Rich Prompts for ALL Questions** - Use `rich.prompt.Prompt` and `rich.prompt.Confirm`, not typer.prompt
3. **Exit Codes:** Config generation failure = EXIT_CONFIG_ERROR (2), user cancellation = EXIT_ERROR (1)
4. **Integration:** Generated config must validate via `load_config_with_project()` (Story 1.4)
5. **Non-Interactive Mode:** `--no-interactive` flag must work; exits with error if config missing
6. **Minimal Config:** Only prompt for essential fields (provider, model) - use sensible defaults for rest
7. **Atomic Write:** Config file must use temp file + rename pattern per architecture.md NFR2

### Blocking Dependencies

| Dependency | Status | Provides |
|------------|--------|----------|
| Story 1.2 | âœ… DONE | Pydantic Config models |
| Story 1.4 | âœ… DONE | `load_config_with_project()` function |
| Story 1.6 | âœ… DONE | CLI entry point with Rich console |
| `rich` | âœ… Available | Rich prompts via typer[all] |

---

## Acceptance Criteria

### AC1: Missing Config Triggers Questionnaire
```gherkin
Given no config file exists at ~/.bmad-assist/config.yaml
And no project config exists at ./bmad-assist.yaml
When user runs `bmad-assist run --project ./my-project`
Then interactive questionnaire starts automatically
And questionnaire displays welcome message with Rich formatting
```

### AC2: Prompts for CLI Provider Selection
```gherkin
Given questionnaire is running
When CLI provider selection is presented
Then user sees list of available providers: claude, codex, gemini
And user can select one provider as Master
And default selection is "claude" (highlighted)
```

### AC3: Prompts for Model Selection
```gherkin
Given CLI provider is selected (e.g., claude)
When model selection is presented
Then user sees list of available models for that provider
And claude options include: opus_4, sonnet_4, sonnet_3_5, haiku_3_5
And default selection is "opus_4" for claude
```

### AC4: Config File Generation
```gherkin
Given all required questions are answered
When questionnaire completes
Then config is saved to ./bmad-assist.yaml
And file contains valid YAML with provider and model settings
And file has proper formatting with comments explaining each section
```

### AC5: Generated Config Validates Successfully
```gherkin
Given config file is generated by questionnaire
When load_config_with_project() is called
Then config loads and validates without error
And all required fields are present with valid values
```

### AC6: Non-Interactive Mode with --no-interactive Flag
```gherkin
Given user runs `bmad-assist run --no-interactive`
And no config file exists
When CLI executes
Then questionnaire does NOT start
And error message displays: "No configuration found. Run without --no-interactive for setup wizard."
And exit code is EXIT_CONFIG_ERROR (2)
```

### AC7: Non-Interactive Mode with Existing Config
```gherkin
Given user runs `bmad-assist run --no-interactive`
And valid config file exists
When CLI executes
Then normal execution proceeds without prompts
And no questionnaire is triggered
```

### AC8: Questionnaire Can Be Cancelled
```gherkin
Given questionnaire is running
When user presses Ctrl+C at any prompt
Then KeyboardInterrupt is raised and propagated
And no partial config file is created
And exit code is EXIT_ERROR (1)

Given questionnaire is running in non-TTY environment (piped input)
When EOFError occurs (no input available)
Then EOFError is raised and propagated
And no partial config file is created
And exit code is EXIT_ERROR (1)
```

### AC9: Default Values for Non-Essential Fields
```gherkin
Given questionnaire is generating config
When config is saved
Then non-essential fields use sensible defaults:
  - state_path: ~/.bmad-assist/state.yaml
  - timeout: 300
  - power_prompt_set: null (optional)
And user is NOT prompted for these defaults
```

### AC10: Confirmation Before Save
```gherkin
Given all questions are answered
When questionnaire prepares to save
Then summary of configuration is displayed
And user is asked "Save this configuration? [Y/n]"
And user must confirm before file is written

Given user rejects save (answers 'n' to confirmation)
When rejection is processed
Then no config file is created
And message "Setup cancelled - no configuration saved" is displayed
And exit code is EXIT_ERROR (1)
```

### AC11: Atomic Write for Config File
```gherkin
Given questionnaire completes and user confirms save
When config is saved to ./bmad-assist.yaml
Then file is written using atomic write pattern (temp file + rename)
And no partial/corrupted config can exist
And if write fails, OSError is raised with clear message
```

---

## Tasks / Subtasks

- [x] Task 1: Create config generator module (AC: 4, 5, 9, 11)
  - [x] 1.1 Create `src/bmad_assist/core/config_generator.py`
  - [x] 1.2 Implement `ConfigGenerator` class with Rich prompts
  - [x] 1.3 Define `AVAILABLE_PROVIDERS` with supported providers and models
  - [x] 1.4 Implement `generate_config()` method returning Config dict
  - [x] 1.5 Implement `_save_config()` method with atomic write (temp file + rename)

- [x] Task 2: Implement questionnaire flow (AC: 1, 2, 3, 10)
  - [x] 2.1 Implement welcome message with project context
  - [x] 2.2 Implement provider selection with `rich.prompt.Prompt.ask(choices=...)`
  - [x] 2.3 Implement model selection based on provider choice
  - [x] 2.4 Implement configuration summary display with Rich table
  - [x] 2.5 Implement save confirmation with `rich.prompt.Confirm.ask()`
  - [x] 2.6 Handle rejection (user answers 'n') - display message, raise SystemExit(1)

- [x] Task 3: Add --no-interactive flag to CLI (AC: 6, 7)
  - [x] 3.1 Add `--no-interactive` / `-n` flag to run command in `cli.py`
  - [x] 3.2 Pass flag to config loading logic
  - [x] 3.3 Handle missing config with proper error message when non-interactive

- [x] Task 4: Integrate questionnaire into CLI flow (AC: 1, 6)
  - [x] 4.1 Detect missing config in `run()` command before loading
  - [x] 4.2 Trigger questionnaire if config missing AND interactive mode
  - [x] 4.3 After questionnaire completes, call `load_config_with_project()` with generated file
  - [x] 4.4 Handle questionnaire cancellation (Ctrl+C, "q")

- [x] Task 5: Handle cancellation and errors (AC: 8, 10, 11)
  - [x] 5.1 Let KeyboardInterrupt propagate to CLI (caught in cli.py)
  - [x] 5.2 Let EOFError propagate for piped input scenarios
  - [x] 5.3 Clean up partial state on cancellation (no partial file)
  - [x] 5.4 Display appropriate cancellation message before raising
  - [x] 5.5 Handle OSError on save with cleanup of temp file

- [x] Task 6: Write comprehensive tests (AC: all)
  - [x] 6.1 Test questionnaire triggers on missing config
  - [x] 6.2 Test provider selection with mocked input
  - [x] 6.3 Test model selection based on provider
  - [x] 6.4 Test generated config validates successfully
  - [x] 6.5 Test --no-interactive flag with missing config
  - [x] 6.6 Test --no-interactive flag with existing config
  - [x] 6.7 Test cancellation handling (KeyboardInterrupt propagation)
  - [x] 6.8 Test EOFError handling (piped input scenario)
  - [x] 6.9 Test confirmation before save (accept)
  - [x] 6.10 Test confirmation rejection (user answers 'n')
  - [x] 6.11 Test atomic write (verify temp file cleanup on failure)
  - [x] 6.12 Achieve >=95% coverage on config_generator.py

---

## Dev Notes

### Critical Architecture Requirements

**From architecture.md - MUST follow exactly:**

1. **CLI Entry Boundary:**
   > "cli.py â†’ only parses args, calls core/loop.py"
   > "No business logic in CLI layer"

   Config generation logic belongs in `core/config_generator.py`, NOT in `cli.py`

2. **Module Location:** `src/bmad_assist/core/config_generator.py` (new file)
3. **Console Output:** Rich prompts for all user interaction
4. **Logging:** `logger = logging.getLogger(__name__)`
5. **Naming Conventions:** PEP8 (snake_case functions, PascalCase classes)
6. **Type Hints:** Required on ALL functions
7. **Docstrings:** Google-style for all public APIs

### Implementation Strategy

**Provider and Model Constants:**
```python
# src/bmad_assist/core/config_generator.py
from typing import Final

AVAILABLE_PROVIDERS: Final[dict[str, dict]] = {
    "claude": {
        "display_name": "Claude (Anthropic)",
        "models": {
            "opus_4": "Claude Opus 4 (Most capable)",
            "sonnet_4": "Claude Sonnet 4 (Fast, capable)",
            "sonnet_3_5": "Claude Sonnet 3.5 (Balanced)",
            "haiku_3_5": "Claude Haiku 3.5 (Fast, economical)",
        },
        "default_model": "opus_4",
    },
    "codex": {
        "display_name": "Codex (OpenAI)",
        "models": {
            "gpt-4o": "GPT-4o (Multimodal)",
            "o3": "o3 (Advanced reasoning)",
        },
        "default_model": "gpt-4o",
    },
    "gemini": {
        "display_name": "Gemini (Google)",
        "models": {
            "gemini_2_5_pro": "Gemini 2.5 Pro",
            "gemini_2_5_flash": "Gemini 2.5 Flash (Fast)",
        },
        "default_model": "gemini_2_5_pro",
    },
}
```

**Rich Prompt Usage:**
```python
from rich.prompt import Prompt, Confirm
from rich.console import Console
from rich.table import Table

console = Console()

def _prompt_provider() -> str:
    """Prompt user to select CLI provider."""
    choices = list(AVAILABLE_PROVIDERS.keys())
    return Prompt.ask(
        "[bold]Select CLI provider[/bold]",
        choices=choices,
        default="claude",
    )

def _prompt_model(provider: str) -> str:
    """Prompt user to select model for provider."""
    provider_info = AVAILABLE_PROVIDERS[provider]
    models = provider_info["models"]
    default = provider_info["default_model"]

    # Display available models with descriptions
    console.print(f"\n[bold]Available models for {provider_info['display_name']}:[/bold]")
    for model_id, description in models.items():
        marker = "[green]â†’[/green]" if model_id == default else "  "
        console.print(f"  {marker} {model_id}: {description}")

    return Prompt.ask(
        "Select model",
        choices=list(models.keys()),
        default=default,
    )
```

**Config YAML Template:**
```python
CONFIG_TEMPLATE = '''# bmad-assist configuration
# Generated by interactive setup wizard

providers:
  master:
    provider: {provider}
    model: {model}
    # Optional: settings_file: ./provider-configs/master-{provider}-{model}.json

# Optional: Multi-LLM validation providers
# multi:
#   - provider: claude
#     model: sonnet_4

# State persistence
state_path: ~/.bmad-assist/state.yaml

# Provider timeout in seconds
timeout: 300
'''
```

### CLI Integration Pattern

**Detecting missing config in cli.py:**
```python
from bmad_assist.core.config_generator import run_config_wizard, CONFIG_FILENAME

@app.command()
def run(
    project: str = typer.Option(...),
    config: str | None = typer.Option(None, ...),
    no_interactive: bool = typer.Option(False, "--no-interactive", "-n",
        help="Disable interactive prompts (fail if config missing)"),
    ...
) -> None:
    """Execute the main BMAD development loop."""
    project_path = _validate_project_path(project)

    # Check if config exists
    config_path = _resolve_config_path(project_path, config)

    if not config_path.exists():
        if no_interactive:
            _error("No configuration found. Run without --no-interactive for setup wizard.")
            raise typer.Exit(code=EXIT_CONFIG_ERROR)

        # Run interactive wizard
        try:
            generated_config_path = run_config_wizard(project_path)
            config_path = generated_config_path
        except KeyboardInterrupt:
            _warning("Setup cancelled by user")
            raise typer.Exit(code=EXIT_ERROR)

    # Continue with normal config loading
    loaded_config = load_config_with_project(project_path, config_path)
    ...
```

### IMPORTANT: Scope Boundaries

**This story handles:**
- Interactive questionnaire for config generation
- Provider and model selection
- Config file creation with sensible defaults
- `--no-interactive` flag implementation
- Cancellation handling

**NOT in scope for this story:**
- Power-prompt set selection (future enhancement - use null default)
- Multi-LLM provider configuration (show commented example only)
- Notification settings (post-MVP)
- Global config at ~/.bmad-assist/config.yaml (only project-local for now)

---

## Technical Requirements

### From PRD (FR38)

| FR | Requirement | This Story's Implementation |
|----|-------------|----------------------------|
| FR38 | System can generate config file via CLI questionnaire when config is missing | Full implementation - interactive wizard with Rich prompts |

### From Architecture

**Configuration Schema (architecture.md):**
```yaml
providers:
  master:
    provider: claude
    model: opus_4
    settings_file: ./provider-configs/master-claude-opus_4.json
  multi:
    - provider: claude
      model: sonnet_4
    - provider: gemini
      model: gemini_2_5_pro

state_path: ~/.bmad-assist/state.yaml
timeout: 300
```

### Dependencies

- **Story 1.2 (DONE):** Pydantic Config models for validation
- **Story 1.4 (DONE):** `load_config_with_project()` - Config loading
- **Story 1.6 (DONE):** CLI entry point with Rich console
- **Existing:** Rich library via typer[all]

### Integration with Existing Code

Story 1.7 integrates with:
1. `load_config_with_project()` - Story 1.4 config loading (validates generated config)
2. `Config` model - Story 1.2 Pydantic validation
3. `cli.py` - Story 1.6 CLI entry point (adds --no-interactive flag)
4. Rich console - Already initialized in cli.py

---

## Architecture Compliance

### Stack Verification
- [x] Python 3.11+ type hints - Required
- [x] Rich prompts - Available via typer[all]
- [x] Pydantic validation - Story 1.2 Config model

### Structure Verification
- [x] Location: `src/bmad_assist/core/config_generator.py` (new file)
- [x] Tests: `tests/core/test_config_generator.py` (new file)
- [x] CLI integration: Extend `cli.py` with --no-interactive flag

### Pattern Verification
- [x] PEP8 naming conventions
- [x] Google-style docstrings
- [x] No business logic in CLI layer (config generation in core/)
- [x] Type hints on all functions

---

## Developer Context

### Git Intelligence Summary

**Recent commits (from git log):**
1. `fix(cli): address AC11 quiet mode and add security comment for Story 1.6`
2. `feat(cli): implement Typer CLI entry point with Rich console for Story 1.6`
3. `docs(story): complete Multi-LLM validation synthesis for story 1.6`
4. `fix(core): address Multi-LLM code review findings for story 1.5`
5. `feat(core): implement .env credential loading for Story 1.5`

**Key Files from Story 1.6:**
- `src/bmad_assist/cli.py` - CLI with Rich console, exit codes, verbose/quiet flags
- `src/bmad_assist/core/loop.py` - Main loop stub
- `tests/test_cli.py` - Comprehensive CLI tests

**Patterns to Follow:**
- Rich console via module-level `console = Console()` in cli.py
- Exit codes: EXIT_SUCCESS=0, EXIT_ERROR=1, EXIT_CONFIG_ERROR=2
- Helper functions: `_error()`, `_success()`, `_warning()` for styled output
- Logger per module: `logger = logging.getLogger(__name__)`
- Tests use `tmp_path` fixture and `monkeypatch` for isolation

### Previous Story Learnings (1.6)

**What worked well:**
- Rich console integration for all user output
- Clear separation: CLI parses args, core/ does logic
- Exit code patterns for different error types

**Code patterns established:**
- `typer.Option(...)` with short forms (-p, -c, -v, -q)
- `_validate_project_path()` returns Path or raises typer.Exit
- `load_config_with_project()` handles missing config gracefully

### Files Modified in Previous Story

**Story 1.6 file list:**
- `src/bmad_assist/cli.py` - Enhanced with Rich, exit codes, run_loop call
- `src/bmad_assist/core/loop.py` - New stub file
- `tests/test_cli.py` - 49 new tests, 96% coverage

### Existing Code to Extend

**From cli.py (Story 1.6 implementation):**
```python
@app.command()
def run(
    project: str = typer.Option(".", "--project", "-p", ...),
    config: str | None = typer.Option(None, "--config", "-c", ...),
    verbose: bool = typer.Option(False, "--verbose", "-v", ...),
    quiet: bool = typer.Option(False, "--quiet", "-q", ...),
) -> None:
```

**To add:** `no_interactive: bool = typer.Option(False, "--no-interactive", "-n", ...)`

---

## File Structure

### Files to Create

| File | Purpose | Lines (est.) |
|------|---------|--------------|
| `src/bmad_assist/core/config_generator.py` | Config generation wizard logic | +120-150 |
| `tests/core/test_config_generator.py` | Tests for config generator | +150-180 |

### Files to Modify

| File | Changes | Lines (est.) |
|------|---------|--------------|
| `src/bmad_assist/cli.py` | Add --no-interactive flag, detect missing config, trigger wizard | +25-35 |
| `src/bmad_assist/core/__init__.py` | Export config generator functions | +2 |
| `tests/test_cli.py` | Add tests for --no-interactive and wizard triggering | +40-50 |

### Expected config_generator.py Structure

```python
"""Configuration generator with interactive questionnaire."""

import logging
from pathlib import Path
from typing import Final

import yaml
from rich.console import Console
from rich.prompt import Prompt, Confirm
from rich.table import Table

logger = logging.getLogger(__name__)

# Provider and model definitions
AVAILABLE_PROVIDERS: Final[dict[str, dict]] = {...}

# Default config filename
CONFIG_FILENAME: Final[str] = "bmad-assist.yaml"


class ConfigGenerator:
    """Interactive configuration generator using Rich prompts."""

    def __init__(self, console: Console | None = None) -> None: ...

    def run(self, project_path: Path) -> Path: ...

    def _prompt_provider(self) -> str: ...

    def _prompt_model(self, provider: str) -> str: ...

    def _display_summary(self, config: dict) -> None: ...

    def _confirm_save(self) -> bool: ...

    def _save_config(self, project_path: Path, config: dict) -> Path: ...


def run_config_wizard(project_path: Path, console: Console | None = None) -> Path:
    """Run the configuration wizard and return path to generated config.

    Args:
        project_path: Path to project directory.
        console: Optional Rich console for output (uses cli.console for consistency).

    Returns:
        Path to the generated config file.

    Raises:
        KeyboardInterrupt: If user cancels with Ctrl+C.
        EOFError: If running in non-interactive environment (piped input).
        OSError: If config file cannot be written (permission denied, disk full).
        SystemExit: If user rejects save confirmation (exit code 1).
    """
    generator = ConfigGenerator(console)
    return generator.run(project_path)
```

---

## Testing Requirements

### Test Cases (tests/core/test_config_generator.py)

```python
"""Tests for Story 1.7: Interactive Config Generation."""

from pathlib import Path
from unittest.mock import patch, MagicMock

import pytest
from rich.console import Console

from bmad_assist.core.config_generator import (
    ConfigGenerator,
    run_config_wizard,
    AVAILABLE_PROVIDERS,
    CONFIG_FILENAME,
)


class TestConfigGenerator:
    """Tests for ConfigGenerator class."""

    def test_available_providers_contains_claude(self) -> None:
        """Verify claude provider is available."""
        assert "claude" in AVAILABLE_PROVIDERS
        assert "opus_4" in AVAILABLE_PROVIDERS["claude"]["models"]

    def test_available_providers_contains_codex(self) -> None:
        """Verify codex provider is available."""
        assert "codex" in AVAILABLE_PROVIDERS

    def test_available_providers_contains_gemini(self) -> None:
        """Verify gemini provider is available."""
        assert "gemini" in AVAILABLE_PROVIDERS


class TestProviderSelection:
    """Tests for provider selection prompt."""

    @patch("bmad_assist.core.config_generator.Prompt.ask")
    def test_prompt_provider_returns_selection(self, mock_ask: MagicMock) -> None:
        """AC2: Provider selection returns user choice."""
        mock_ask.return_value = "claude"
        generator = ConfigGenerator()
        result = generator._prompt_provider()
        assert result == "claude"

    @patch("bmad_assist.core.config_generator.Prompt.ask")
    def test_prompt_provider_default_is_claude(self, mock_ask: MagicMock) -> None:
        """AC2: Default provider is claude."""
        generator = ConfigGenerator()
        generator._prompt_provider()
        mock_ask.assert_called_once()
        call_kwargs = mock_ask.call_args[1]
        assert call_kwargs.get("default") == "claude"


class TestModelSelection:
    """Tests for model selection prompt."""

    @patch("bmad_assist.core.config_generator.Prompt.ask")
    def test_prompt_model_for_claude(self, mock_ask: MagicMock) -> None:
        """AC3: Model selection for claude shows opus_4 as default."""
        mock_ask.return_value = "opus_4"
        generator = ConfigGenerator()
        result = generator._prompt_model("claude")
        assert result == "opus_4"


class TestConfigGeneration:
    """Tests for config file generation."""

    @patch("bmad_assist.core.config_generator.Prompt.ask")
    @patch("bmad_assist.core.config_generator.Confirm.ask")
    def test_generates_valid_yaml(
        self, mock_confirm: MagicMock, mock_prompt: MagicMock, tmp_path: Path
    ) -> None:
        """AC4: Generated config is valid YAML."""
        mock_prompt.side_effect = ["claude", "opus_4"]
        mock_confirm.return_value = True

        config_path = run_config_wizard(tmp_path)

        assert config_path.exists()
        import yaml
        with open(config_path) as f:
            config = yaml.safe_load(f)
        assert config is not None
        assert "providers" in config

    @patch("bmad_assist.core.config_generator.Prompt.ask")
    @patch("bmad_assist.core.config_generator.Confirm.ask")
    def test_config_validates_with_pydantic(
        self, mock_confirm: MagicMock, mock_prompt: MagicMock, tmp_path: Path
    ) -> None:
        """AC5: Generated config validates with load_config_with_project."""
        mock_prompt.side_effect = ["claude", "opus_4"]
        mock_confirm.return_value = True

        config_path = run_config_wizard(tmp_path)

        from bmad_assist.core.config import load_config_with_project
        # Should not raise
        config = load_config_with_project(tmp_path, config_path)
        assert config is not None


class TestCancellation:
    """Tests for cancellation handling."""

    @patch("bmad_assist.core.config_generator.Prompt.ask")
    def test_keyboard_interrupt_raises(self, mock_ask: MagicMock, tmp_path: Path) -> None:
        """AC8: KeyboardInterrupt propagates to caller."""
        mock_ask.side_effect = KeyboardInterrupt()

        with pytest.raises(KeyboardInterrupt):
            run_config_wizard(tmp_path)

    @patch("bmad_assist.core.config_generator.Prompt.ask")
    def test_eof_error_raises(self, mock_ask: MagicMock, tmp_path: Path) -> None:
        """AC8: EOFError propagates to caller (piped input scenario)."""
        mock_ask.side_effect = EOFError()

        with pytest.raises(EOFError):
            run_config_wizard(tmp_path)

    @patch("bmad_assist.core.config_generator.Prompt.ask")
    def test_no_partial_file_on_cancel(self, mock_ask: MagicMock, tmp_path: Path) -> None:
        """AC8: No partial config file on cancellation."""
        mock_ask.side_effect = KeyboardInterrupt()
        config_path = tmp_path / CONFIG_FILENAME

        with pytest.raises(KeyboardInterrupt):
            run_config_wizard(tmp_path)

        assert not config_path.exists()


class TestConfirmation:
    """Tests for save confirmation."""

    @patch("bmad_assist.core.config_generator.Prompt.ask")
    @patch("bmad_assist.core.config_generator.Confirm.ask")
    def test_no_save_on_rejection(
        self, mock_confirm: MagicMock, mock_prompt: MagicMock, tmp_path: Path
    ) -> None:
        """AC10: Config not saved if user rejects."""
        mock_prompt.side_effect = ["claude", "opus_4"]
        mock_confirm.return_value = False

        with pytest.raises(SystemExit) as exc_info:
            run_config_wizard(tmp_path)

        assert exc_info.value.code == 1  # EXIT_ERROR
        config_path = tmp_path / CONFIG_FILENAME
        assert not config_path.exists()


class TestAtomicWrite:
    """Tests for atomic write pattern."""

    @patch("bmad_assist.core.config_generator.Prompt.ask")
    @patch("bmad_assist.core.config_generator.Confirm.ask")
    @patch("bmad_assist.core.config_generator.os.rename")
    def test_temp_file_cleanup_on_rename_failure(
        self, mock_rename: MagicMock, mock_confirm: MagicMock, mock_prompt: MagicMock, tmp_path: Path
    ) -> None:
        """AC11: Temp file cleaned up if rename fails."""
        mock_prompt.side_effect = ["claude", "opus_4"]
        mock_confirm.return_value = True
        mock_rename.side_effect = OSError("Rename failed")

        with pytest.raises(OSError):
            run_config_wizard(tmp_path)

        # Verify no temp files left behind
        temp_files = list(tmp_path.glob(".bmad-assist-*.yaml.tmp"))
        assert len(temp_files) == 0
```

### CLI Tests (tests/test_cli.py additions)

```python
class TestNoInteractiveFlag:
    """Tests for --no-interactive flag."""

    def test_no_interactive_flag_accepted(self) -> None:
        """AC6: --no-interactive flag is recognized."""
        result = runner.invoke(app, ["run", "--no-interactive", "--help"])
        assert "--no-interactive" in result.output

    def test_no_interactive_short_form(self) -> None:
        """AC6: -n short form works."""
        result = runner.invoke(app, ["run", "-n", "--help"])
        assert result.exit_code == 0

    def test_no_interactive_missing_config_errors(self, tmp_path: Path) -> None:
        """AC6: Missing config with --no-interactive exits with error."""
        result = runner.invoke(app, [
            "run",
            "--project", str(tmp_path),
            "--no-interactive",
        ])
        assert result.exit_code == EXIT_CONFIG_ERROR
        assert "configuration" in result.output.lower()
```

### Coverage Target
- **>=95% coverage** on config_generator.py
- All prompt paths tested via mocking
- Cancellation and error handling tested
- Integration with config loading tested

### Mocking Strategy
- Mock `rich.prompt.Prompt.ask()` for user input simulation
- Mock `rich.prompt.Confirm.ask()` for confirmation simulation
- Use `tmp_path` fixture for file operations
- Test actual YAML output for format verification

---

## Library/Framework Requirements

### Rich Prompts Usage

```python
from rich.prompt import Prompt, Confirm, IntPrompt
from rich.console import Console

console = Console()

# Simple text prompt with choices
provider = Prompt.ask(
    "[bold]Select provider[/bold]",
    choices=["claude", "codex", "gemini"],
    default="claude",
)

# Confirmation prompt
if Confirm.ask("Save configuration?", default=True):
    save_config()

# Display formatted output
console.print("[green]âœ“[/green] Configuration saved to bmad-assist.yaml")
```

### Rich Table for Summary Display

```python
from rich.table import Table

def _display_summary(self, config: dict) -> None:
    """Display configuration summary in a table."""
    table = Table(title="Configuration Summary")
    table.add_column("Setting", style="cyan")
    table.add_column("Value", style="green")

    table.add_row("Provider", config["providers"]["master"]["provider"])
    table.add_row("Model", config["providers"]["master"]["model"])
    table.add_row("Config file", "bmad-assist.yaml")

    self.console.print(table)
```

### YAML Output with Comments (Atomic Write Pattern)

```python
import os
import tempfile
import yaml

def _save_config(self, project_path: Path, config: dict) -> Path:
    """Save config to YAML file using atomic write pattern.

    Uses temp file + os.rename() per architecture.md NFR2 requirements
    to ensure no partial/corrupted config files can exist.

    Raises:
        OSError: If write fails (permission denied, disk full, etc.)
    """
    config_path = project_path / CONFIG_FILENAME

    # Write header comment separately (yaml.dump doesn't preserve comments)
    header = """# bmad-assist configuration
# Generated by interactive setup wizard
# See docs/architecture.md for full schema

"""
    content = header + yaml.dump(config, default_flow_style=False, sort_keys=False)

    # Atomic write: temp file in same directory + rename
    # Same directory ensures same filesystem for atomic rename
    fd, tmp_path = tempfile.mkstemp(
        dir=project_path,
        prefix=".bmad-assist-",
        suffix=".yaml.tmp"
    )
    try:
        with os.fdopen(fd, "w") as f:
            f.write(content)
        os.rename(tmp_path, config_path)  # Atomic on POSIX
    except Exception:
        # Clean up temp file on failure
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)
        raise

    return config_path
```

---

## Project Context Reference

**Project:** bmad-assist - CLI tool for automating BMAD methodology development loop

**Key Architecture Patterns:**
- Config via `load_config_with_project()` - Story 1.4
- CLI boundary: parse args, call core/ - No business logic in cli.py
- Rich console for all user-facing output
- Logging via `logger = logging.getLogger(__name__)`

**Critical Rules:**
- Python 3.11+, PEP8 naming, type hints on all functions
- Google-style docstrings for public APIs
- Test coverage >=95% on new code
- mypy strict mode, ruff linting
- **No business logic in CLI layer** - config_generator.py in core/

---

## References

- [Source: docs/architecture.md#Configuration] - Config schema and validation
- [Source: docs/architecture.md#CLI-Entry-Boundary] - CLI only parses args
- [Source: docs/prd.md#FR38] - Config generation via CLI questionnaire
- [Source: docs/epics.md#Story-1.7] - Original story definition
- [Source: Story 1.2] - Pydantic Config models
- [Source: Story 1.4] - load_config_with_project() integration
- [Source: Story 1.6] - CLI entry point with Rich console

---

## Verification Checklist

Before marking as complete, verify:

**Config Generator Implementation:**
- [ ] `config_generator.py` created in `core/`
- [ ] AVAILABLE_PROVIDERS constant with claude, codex, gemini
- [ ] ConfigGenerator class with Rich prompts
- [ ] `run_config_wizard()` function exported
- [ ] Provider selection with default="claude"
- [ ] Model selection based on provider
- [ ] Config summary display with Rich table
- [ ] Save confirmation with Confirm.ask()
- [ ] Rejection handling (user answers 'n') - displays message, raises SystemExit(1)
- [ ] YAML file generation with atomic write (temp file + rename)
- [ ] KeyboardInterrupt propagation (no partial file)
- [ ] EOFError propagation for piped input (no partial file)
- [ ] OSError handling with temp file cleanup

**CLI Integration:**
- [ ] `--no-interactive` / `-n` flag added to run command
- [ ] Missing config detection before loading
- [ ] Wizard triggered when config missing AND interactive
- [ ] Proper error message when non-interactive + missing config
- [ ] Exit code EXIT_CONFIG_ERROR (2) on config issues

**Quality Gates:**
- [ ] `mypy src/` reports no errors
- [ ] `ruff check src/` reports no issues
- [ ] `pytest tests/` passes all tests
- [ ] Coverage >=95% on config_generator.py

---

## Dev Agent Record

### Context Reference
- Story ID: 1.7
- Story Key: 1-7-interactive-config-generation
- Epic: 1 - Project Foundation & CLI Infrastructure
- Previous Story: 1.6 (review) - Typer CLI Entry Point

### Agent Model Used
Claude Opus 4.5 (claude-opus-4-5-20251101)

### Debug Log References
- All 294 tests pass
- mypy: 0 errors
- ruff: All checks passed
- Coverage: config_generator.py 100%, cli.py 97%

### Completion Notes List
- âœ… Created `config_generator.py` with `ConfigGenerator` class and `run_config_wizard()` function
- âœ… Implemented provider selection with claude, codex, gemini options (default: claude)
- âœ… Implemented model selection based on provider (claude default: opus_4)
- âœ… Implemented Rich Table summary display before save confirmation
- âœ… Implemented save confirmation with `Confirm.ask()`, rejection raises SystemExit(1)
- âœ… Added `--no-interactive` / `-n` flag to CLI run command
- âœ… Integrated wizard into CLI flow - triggers when config missing and interactive mode
- âœ… KeyboardInterrupt and EOFError propagate correctly, no partial files created
- âœ… Atomic write pattern using temp file + os.rename() per architecture NFR2
- âœ… Generated config validates successfully with `load_config_with_project()`
- âœ… 54 tests for config_generator.py (100% coverage)
- âœ… 16 new tests in test_cli.py for --no-interactive and wizard integration

### Change Log
- 2025-12-10: Implemented interactive config generation wizard (Story 1.7)

### File List
**Created:**
- `src/bmad_assist/core/config_generator.py` - Config generator module with wizard
- `tests/core/test_config_generator.py` - Comprehensive tests for config generator

**Modified:**
- `src/bmad_assist/cli.py` - Added --no-interactive flag, _config_exists helper, wizard integration
- `src/bmad_assist/core/__init__.py` - Exported config generator functions
- `tests/test_cli.py` - Added tests for --no-interactive flag and wizard integration
